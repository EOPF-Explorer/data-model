{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOPF Zarr Explorer Sentinel-2 L2A Data Structure Analysis\n",
    "\n",
    "This notebook analyzes the EOPF (Earth Observation Processing Framework) Sentinel-2 L2A Zarr dataset structure\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Data Structure Analysis**: Complete inventory of EOPF Sentinel-2 L2A dataset structure, chunking, and compression\n",
    "2. **Hierarchy Size Analysis**: Display the size of the hierarchy data structure with sums at group level\n",
    "3. **Metadata Analysis**: Analyze current metadata conventions and CRS handling\n",
    "4. **Performance Analysis**: Identify bottlenecks for web access patterns\n",
    "5. **Optimization Recommendations**: Document findings with recommendations for optimization\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**Target Dataset**: `s2l2_test.zarr`\n",
    "- **Product Type**: Sentinel-2 Level 2A (Bottom-of-Atmosphere reflectance)\n",
    "- **Processing Level**: L2A (atmospherically corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import warnings\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our analysis utilities\n",
    "from eopf_analysis_utils import (\n",
    "    load_eopf_dataset,\n",
    "    analyze_hierarchy_sizes,\n",
    "    print_hierarchy_sizes\n",
    ")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"✅ Libraries and utilities imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATASET_URL = \"/home/emathot/Workspace/eopf-explorer/data-model/tests-output/eopf_geozarr/s2l2_test.zarr\"\n",
    "\n",
    "print(f\"🌐 Dataset URL: {DATASET_URL}\")\n",
    "\n",
    "from xarray.namedarray.parallelcompat import list_chunkmanagers\n",
    "chunk_managers = list_chunkmanagers()\n",
    "for cm in chunk_managers:\n",
    "    print(f\"Chunk manager: {cm}\")\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client()  # set up local cluster on your laptop\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EOPF dataset\n",
    "zarr_store, datatree = load_eopf_dataset(DATASET_URL)\n",
    "\n",
    "print(f\"\\n📁 Store keys: {list(zarr_store.keys())}\")\n",
    "print(f\"🌳 Datatree groups: {list(datatree.groups)}\")\n",
    "print(f\"📊 Datatree variables: {list(datatree.variables)}\")\n",
    "\n",
    "# Display basic structure\n",
    "print(\"\\n=== Zarr Store Structure ===\")\n",
    "print(zarr_store.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchy Size Analysis\n",
    "\n",
    "This section analyzes the size of the hierarchy data structure with sums at group level, providing insights into data distribution and storage requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hierarchy sizes with group-level sums using xarray\n",
    "size_analysis = analyze_hierarchy_sizes(datatree, zarr_store)\n",
    "\n",
    "# Display hierarchy sizes in tree format\n",
    "print_hierarchy_sizes(size_analysis, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional size statistics\n",
    "print(f\"\\n📈 DETAILED SIZE STATISTICS:\")\n",
    "print(f\"  Total arrays: {len(size_analysis['array_sizes'])}\")\n",
    "print(f\"  Total groups: {len(size_analysis['group_sizes'])}\")\n",
    "print(f\"  Hierarchy levels: {len(size_analysis['summary_by_level'])}\")\n",
    "\n",
    "# Show largest arrays\n",
    "print(f\"\\n🔍 LARGEST ARRAYS (Top 10):\")\n",
    "sorted_arrays = sorted(size_analysis['array_sizes'].items(), \n",
    "                      key=lambda x: x[1]['size_bytes'], reverse=True)\n",
    "\n",
    "for i, (array_path, array_info) in enumerate(sorted_arrays[:10]):\n",
    "    shape_str = \"x\".join(map(str, array_info['shape']))\n",
    "    print(f\"  {i+1:2d}. {array_path}: {array_info['size_formatted']} ({shape_str}, {array_info['dtype']})\")\n",
    "\n",
    "# Show group size distribution\n",
    "print(f\"\\n📊 GROUP SIZE DISTRIBUTION:\")\n",
    "for level, level_info in sorted(size_analysis['summary_by_level'].items()):\n",
    "    avg_group_size = level_info['total_size_bytes'] / level_info['group_count'] if level_info['group_count'] > 0 else 0\n",
    "    from eopf_analysis_utils import format_size\n",
    "    print(f\"  Level {level}: {level_info['group_count']} groups, avg size: {format_size(int(avg_group_size))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-Level Size Summary\n",
    "\n",
    "Detailed breakdown of sizes by major groups in the EOPF hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze major group categories\n",
    "print(\"\\n🔍 MAJOR GROUP ANALYSIS:\")\n",
    "\n",
    "major_groups = ['measurements', 'quality', 'conditions']\n",
    "for group_name in major_groups:\n",
    "    if group_name in size_analysis['group_sizes']:\n",
    "        group_info = size_analysis['group_sizes'][group_name]\n",
    "        print(f\"\\n📁 {group_name.upper()} GROUP:\")\n",
    "        print(f\"  Total size: {group_info['size_formatted']}\")\n",
    "        print(f\"  Arrays: {group_info['array_count']}\")\n",
    "        print(f\"  Subgroups: {group_info['subgroup_count']}\")\n",
    "        \n",
    "        # Show percentage of total dataset\n",
    "        percentage = (group_info['size_bytes'] / size_analysis['total_size_bytes']) * 100\n",
    "        print(f\"  Percentage of total: {percentage:.1f}%\")\n",
    "\n",
    "# Show resolution group breakdown for measurements\n",
    "print(f\"\\n📊 RESOLUTION GROUP BREAKDOWN:\")\n",
    "resolution_groups = {}\n",
    "for group_path, group_info in size_analysis['group_sizes'].items():\n",
    "    if 'measurements/reflectance/' in group_path:\n",
    "        parts = group_path.split('/')\n",
    "        if len(parts) >= 3 and parts[2].startswith('r') and parts[2].endswith('m'):\n",
    "            res_group = parts[2]\n",
    "            if res_group not in resolution_groups:\n",
    "                resolution_groups[res_group] = {\n",
    "                    'size_bytes': 0,\n",
    "                    'array_count': 0\n",
    "                }\n",
    "            resolution_groups[res_group]['size_bytes'] += group_info['size_bytes']\n",
    "            resolution_groups[res_group]['array_count'] += group_info['array_count']\n",
    "\n",
    "for res_group, info in sorted(resolution_groups.items()):\n",
    "    from eopf_analysis_utils import format_size\n",
    "    print(f\"  {res_group}: {format_size(info['size_bytes'])} ({info['array_count']} arrays)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis provides comprehensive insights into:\n",
    "\n",
    "1. **Hierarchy Structure Sizes**: Complete breakdown of data sizes at each level with group-level sums\n",
    "2. **Data Distribution**: Understanding of how data is distributed across the hierarchy\n",
    "3. **Storage Requirements**: Detailed size information for capacity planning\n",
    "4. **Resolution Analysis**: Breakdown by spatial resolution groups (r10m, r20m, r60m)\n",
    "5. **Group Categories**: Analysis of measurements, quality, and conditions groups\n",
    "\n",
    "The hierarchy size analysis is particularly useful for:\n",
    "- Understanding data volume distribution across groups\n",
    "- Identifying the largest data components\n",
    "- Planning storage and bandwidth requirements\n",
    "- Optimizing data access patterns\n",
    "- Comparing sizes across different resolution levels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
